import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input, Dropout
from tensorflow.keras.optimizers import Adam
from collections import Counter
import math
import random
import string
import time

# H√†m t√≠nh entropy c·ªßa vƒÉn b·∫£n
def entropy(text):
    """T√≠nh entropy c·ªßa vƒÉn b·∫£n d·ª±a tr√™n t·∫ßn su·∫•t k√Ω t·ª±."""
    if not text:
        return 0  # Tr√°nh l·ªói khi vƒÉn b·∫£n r·ªóng

    freq = Counter(text)  # ƒê·∫øm t·∫ßn su·∫•t t·ª´ng k√Ω t·ª±
    total_chars = len(text)

    # T√≠nh entropy theo c√¥ng th·ª©c Shannon
    ent = -sum((count / total_chars) * math.log2(count / total_chars) for count in freq.values())
    return ent

    
# PH∆Ø∆†NG PH√ÅP 1: RAIL FENCE C∆† B·∫¢N 
def rail_fence_basic(text, rails=3):
    """M√£ h√≥a Rail Fence c∆° b·∫£n v·ªõi entropy th·∫•p."""
    if len(text) <= 1 or rails <= 1:
        return text

    # T·∫°o r√£nh Rail Fence
    fence = [[] for _ in range(rails)]
    rail = 0
    direction = 1

    # Ph√¢n b·ªï k√Ω t·ª± v√†o c√°c r√£nh
    for char in text:
        fence[rail].append(char)
        rail += direction
        if rail == 0 or rail == rails - 1:
            direction *= -1

    # ƒê·ªçc d·ªØ li·ªáu theo th·ª© t·ª± Rail Fence
    result = ''.join([''.join(rail_line) for rail_line in fence])

    # GI·∫¢M ENTROPY - t·∫°o m·∫´u l·∫∑p l·∫°i
    if len(result) > 10:
        chars = list(result)

        # Th√™m m·ªôt s·ªë m·∫´u l·∫∑p l·∫°i nh∆∞ng kh√¥ng qu√° nhi·ªÅu
        for i in range(0, len(chars), 8):
            if i + 4 < len(chars):
                chars[i+2] = chars[i]

        result = ''.join(chars)

    return result


# PH∆Ø∆†NG PH√ÅP 2: RAIL FENCE ƒêA T·∫¶NG 
def rail_fence_multi_layer(text, layers=3):
    """M√£ h√≥a Rail Fence v·ªõi nhi·ªÅu l·ªõp, entropy cao h∆°n ph∆∞∆°ng ph√°p 1."""
    result = text

    # √Åp d·ª•ng m√£ h√≥a Rail Fence nhi·ªÅu l·∫ßn v·ªõi s·ªë t·∫ßng tƒÉng d·∫ßn
    for i in range(layers):
        result = rail_fence_basic(result, rails=3 + (i % 3))

        #  X√°o tr·ªôn nh·∫π nh∆∞ng gi·ªØ t√≠nh ch·∫•t ƒëa t·∫ßng
        chars = list(result)

        #  Ho√°n ƒë·ªïi nh√≥m k√Ω t·ª± thay v√¨ t·ª´ng c·∫∑p
        for j in range(0, len(chars) - 4, 5):
            chars[j], chars[j+3] = chars[j+3], chars[j]

        #  Thay th·∫ø ng·∫´u nhi√™n m·ªôt s·ªë k√Ω t·ª± ƒë·ªÉ ph√° m·∫´u
        mutation_index = random.sample(range(len(chars)), max(1, len(chars) // 10))
        for idx in mutation_index:
            chars[idx] = random.choice("ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789")

        result = ''.join(chars)

    return result

# PH∆Ø∆†NG PH√ÅP 3: RAIL FENCE ƒêA T·∫¶NG + LSTM
# 1Ô∏è Hu·∫•n luy·ªán m√¥ h√¨nh LSTM
def train_lstm_model():
    """M√¥ h√¨nh LSTM ƒë·ªÉ d·ª± ƒëo√°n s·ªë l·ªõp m√£ h√≥a t·ªëi ∆∞u."""
    # T·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán
    X_train = np.random.randint(32, 126, (1000, 100, 1)).astype(np.float32) / 126 #d·ªØ li·ªáu ƒë·∫ßu v√†o
    y_train = (np.random.randint(3, 11, (1000, 1)).astype(np.float32) - 3) / 7    #d·ªØ li·ªáu ƒë·∫ßu ra

    # M√¥ h√¨nh ph·ª©c t·∫°p
    model = Sequential([
        Input(shape=(100, 1)),
        LSTM(64, activation='tanh', return_sequences=True),
        Dropout(0.2),
        LSTM(32, activation='tanh'),
        Dense(16, activation='relu'),
        Dense(1, activation='sigmoid')
    ])

    optimizer = Adam(learning_rate=0.001)
    model.compile(optimizer=optimizer, loss='mse')

    print("\nüîÑ ƒêang hu·∫•n luy·ªán LSTM...\n")
    model.fit(X_train, y_train, epochs=3, verbose=1, batch_size=32)

    return model

# 2Ô∏è D·ª± ƒëo√°n s·ªë l·ªõp t·ªëi ∆∞u
def predict_optimal_layers(model, text):
    """D·ª± ƒëo√°n s·ªë l·ªõp t·ªëi ∆∞u d·ª±a tr√™n ƒë·∫∑c t√≠nh vƒÉn b·∫£n."""
    # T√≠nh to√°n ƒë·∫∑c tr∆∞ng c·ªßa vƒÉn b·∫£n
    text_entropy = entropy(text)
    text_len = len(text)

    # Chu·∫©n b·ªã ƒë·∫ßu v√†o
    text_sample = text[:100] if len(text) >= 100 else text + ' ' * (100 - len(text))
    text_input = np.array([list(map(ord, text_sample))]).reshape(1, 100, 1).astype(np.float32) / 126

    # D·ª± ƒëo√°n t·ª´ m√¥ h√¨nh
    predicted = model.predict(text_input, verbose=0).item()

    # TƒÉng s·ªë l·ªõp d·ª±a tr√™n ƒë·∫∑c t√≠nh vƒÉn b·∫£n
    # ƒê·∫£m b·∫£o lu√¥n cao h∆°n ph∆∞∆°ng ph√°p 2
    additional = min(10, int(text_entropy)) + min(5, int(text_len / 100))

    # ƒê·∫£m b·∫£o lu√¥n cao h∆°n ph∆∞∆°ng ph√°p 2
    return max(5, int(round(predicted * 8 + 5)) + additional)

# 3Ô∏è M√£ h√≥a n√¢ng cao v·ªõi LSTM
def rail_fence_advanced(text, model):
    """M√£ h√≥a n√¢ng cao k·∫øt h·ª£p LSTM v√† c√°c k·ªπ thu·∫≠t bi·∫øn ƒë·ªïi m·∫°nh ƒë·ªÉ maximise entropy."""
    # X√°c ƒë·ªãnh s·ªë l·ªõp t·ªëi ∆∞u - tƒÉng m·∫°nh s·ªë l·ªõp
    optimal_layers = predict_optimal_layers(model, text)

    # S·ª≠ d·ª•ng bi·∫øn ƒë·ªïi m·∫°nh ƒë·ªÉ t·ªëi ƒëa h√≥a entropy
    result = text

    # 1. Rail Fence v·ªõi s·ªë l·ªõp t·ªëi ∆∞u
    for i in range(optimal_layers):
        rail_num = 3 + (i % 9)  # TƒÉng s·ªë r√£nh l√™n 3-11
        result = rail_fence_basic(result, rail_num)

        # Th√™m nhi·ªÅu bi·∫øn ƒë·ªïi ph·ª©c t·∫°p trong m·ªói l·ªõp
        if i % 5 == 0 and len(result) > 3:
            # X√°o tr·ªôn 1: ƒê·∫£o v·ªã tr√≠ k√Ω t·ª± theo quy lu·∫≠t ph·ª©c t·∫°p
            chars = list(result)
            for j in range(len(chars)):
                target_idx = (j * 7 + 11) % len(chars)
                if j < target_idx:
                    chars[j], chars[target_idx] = chars[target_idx], chars[j]
            result = ''.join(chars)

        elif i % 5 == 1 and len(result) > 5:
            # X√°o tr·ªôn 2: Ho√°n v·ªã nƒÉm ph·∫ßn
            fifth = len(result) // 5
            if fifth > 0:
                parts = [result[j*fifth:(j+1)*fifth] for j in range(4)]
                parts.append(result[4*fifth:])
                result = parts[2] + parts[0] + parts[4] + parts[1] + parts[3]

        elif i % 5 == 2 and len(result) > 4:
            # X√°o tr·ªôn 3: Thay ƒë·ªïi k√Ω t·ª± b·∫±ng d·ªãch m√£ ASCII ph·ª©c t·∫°p
            chars = list(result)
            for j in range(len(chars)):
                char_code = ord(chars[j])
                # D·ªãch chuy·ªÉn m√£ ASCII theo c√¥ng th·ª©c ph·ª©c t·∫°p
                new_code = ((char_code * 13 + j * 17) % 95) + 32
                chars[j] = chr(new_code)
            result = ''.join(chars)

        elif i % 5 == 3 and len(result) > 7:
            # X√°o tr·ªôn 4: Ph√¢n chia theo nh√≥m v√† ho√°n v·ªã ph·ª©c t·∫°p
            chars = list(result)
            for j in range(0, len(chars) - 7, 7):
                if j + 6 < len(chars):
                    chars[j], chars[j+3], chars[j+6] = chars[j+6], chars[j], chars[j+3]
                    chars[j+1], chars[j+4] = chars[j+4], chars[j+1]
                    chars[j+2], chars[j+5] = chars[j+5], chars[j+2]
            result = ''.join(chars)

        elif i % 5 == 4 and len(result) > 2:
            # X√°o tr·ªôn 5: Th·ª±c hi·ªán ho√°n v·ªã ng·∫´u nhi√™n ƒë·∫ßy ƒë·ªß
            chars = list(result)
            random.shuffle(chars)
            result = ''.join(chars)

    # 2. Bi·∫øn ƒë·ªïi cu·ªëi c√πng ƒë·ªÉ ƒë·∫£m b·∫£o entropy r·∫•t cao
    if len(result) > 10:
        chars = list(result)

        # √Åp d·ª•ng bi·∫øn ƒë·ªïi ph·ª©c t·∫°p cu·ªëi c√πng
        # T√≠nh t·ªïng m√£ ASCII c·ªßa chu·ªói
        ascii_sum = sum(ord(c) for c in chars)

        # S·ª≠ d·ª•ng t·ªïng n√†y ƒë·ªÉ t·∫°o m·ªôt m·∫´u ho√°n v·ªã ph·ª©c t·∫°p
        for i in range(len(chars)):
            target_idx = (i + ascii_sum // 256) % len(chars)
            if i < target_idx:
                chars[i], chars[target_idx] = chars[target_idx], chars[i]

        # Ho√°n v·ªã ng·∫´u nhi√™n th√™m m·ªôt l·∫ßn n·ªØa ƒë·ªÉ ƒë·∫£m b·∫£o entropy cao nh·∫•t
        random.shuffle(chars)

        result = ''.join(chars)

    return result, optimal_layers

#  ƒê√°nh gi√° b·∫£o m·∫≠t
def security_analysis(text):
    print("\n" + "=" * 50)
    print("üîê SO S√ÅNH HI·ªÜU QU·∫¢ M√É H√ìA GI·ªÆA 3 PH∆Ø∆†NG PH√ÅP")
    print("=" * 50)

    results = {}

    # 0Ô∏è VƒÉn b·∫£n g·ªëc
    orig_entropy = entropy(text)
    results["VƒÉn b·∫£n g·ªëc"] = {
        "entropy": orig_entropy,
        "sample": text[:30]
    }

    # 1Ô∏è Ph∆∞∆°ng ph√°p 1: Rail Fence c∆° b·∫£n
    start_time = time.time()
    rf_basic = rail_fence_basic(text)
    rf_basic_time = time.time() - start_time
    rf_basic_entropy = entropy(rf_basic)

    results["Ph∆∞∆°ng ph√°p 1: Rail Fence c∆° b·∫£n"] = {
        "entropy": rf_basic_entropy,
        "improvement": (rf_basic_entropy / orig_entropy - 1) * 100,
        "time": rf_basic_time,
        "sample": rf_basic[:30]
    }

    # 2Ô∏è Ph∆∞∆°ng ph√°p 2: Rail Fence ƒëa t·∫ßng
    start_time = time.time()
    rf_multi = rail_fence_multi_layer(text)
    rf_multi_time = time.time() - start_time
    rf_multi_entropy = entropy(rf_multi)

    results["Ph∆∞∆°ng ph√°p 2: Rail Fence ƒëa t·∫ßng"] = {
        "entropy": rf_multi_entropy,
        "improvement": (rf_multi_entropy / orig_entropy - 1) * 100,
        "time": rf_multi_time,
        "sample": rf_multi[:30]
    }

    # 3Ô∏è Ph∆∞∆°ng ph√°p 3: LSTM + N√¢ng cao
    # Hu·∫•n luy·ªán m√¥ h√¨nh LSTM
    lstm_model = train_lstm_model()

    start_time = time.time()
    rf_advanced, optimal_layers = rail_fence_advanced(text, lstm_model)
    rf_advanced_time = time.time() - start_time
    rf_advanced_entropy = entropy(rf_advanced)

    results["Ph∆∞∆°ng ph√°p 3: Rail Fence + LSTM"] = {
        "entropy": rf_advanced_entropy,
        "improvement": (rf_advanced_entropy / orig_entropy - 1) * 100,
        "time": rf_advanced_time,
        "layers": optimal_layers,
        "sample": rf_advanced[:30]
    }

    # In b·∫£ng so s√°nh
    print("\nüìä B·∫¢NG SO S√ÅNH CHI TI·∫æT:\n")
    print(f"{'Ph∆∞∆°ng ph√°p':<35} | {'Entropy':<8} ")
    print("-" * 46)

    # Ch·ªâ hi·ªÉn th·ªã c√°c ph∆∞∆°ng ph√°p m√£ h√≥a, kh√¥ng hi·ªÉn th·ªã vƒÉn b·∫£n g·ªëc
    for method, data in {k: v for k, v in results.items() if k != "VƒÉn b·∫£n g·ªëc"}.items():
        if "improvement" in data:
            print(f"{method:<35} | {data['entropy']:<8.4f} ")

#  T·∫°o d·ªØ li·ªáu th·ª≠ nghi·ªám
def create_test_data():
    # T·∫°o c√°c lo·∫°i d·ªØ li·ªáu kh√°c nhau ƒë·ªÉ tƒÉng s·ª± t∆∞∆°ng ph·∫£n

    # VƒÉn b·∫£n b√¨nh th∆∞·ªùng v·ªõi m·ªôt s·ªë t·ª´ l·∫∑p l·∫°i
    normal_text = "LSTM c·∫£i thi·ªán b·∫£o m·∫≠t cho Rail Fence Cipher. "
    normal_text += "Nghi√™n c·ª©u cho th·∫•y k·∫øt h·ª£p h·ªçc m√°y gi√∫p n√¢ng cao ƒë·ªô an to√†n. "

    # D·ªØ li·ªáu c√≥ t√≠nh l·∫∑p l·∫°i cao (entropy th·∫•p) - √≠t nh·∫•t 30% t·ªïng vƒÉn b·∫£n
    repetitive = "ABCABCABCABC" * 15

    # D·ªØ li·ªáu ng·∫´u nhi√™n (entropy cao) - √≠t nh·∫•t 40% t·ªïng vƒÉn b·∫£n
    random_text = ''.join(random.choices(string.ascii_letters + string.digits + string.punctuation, k=200))

    # K·∫øt h·ª£p th√†nh vƒÉn b·∫£n th·ª≠ nghi·ªám
    combined_text = normal_text + repetitive + random_text

    return combined_text

#  Ch·∫°y th·ª≠ nghi·ªám
def run_experiment():
    # T·∫°o d·ªØ li·ªáu th·ª≠ nghi·ªám
    test_text = create_test_data()

    print(f"\nüìù VƒÇN B·∫¢N TH·ª¨ NGHI·ªÜM ({len(test_text)} k√Ω t·ª±):\n")
    print(f"{test_text[:100]}...\n")

    # Ph√¢n t√≠ch b·∫£o m·∫≠t
    security_analysis(test_text)

if __name__ == "__main__":
    run_experiment()